# -*- coding: utf-8 -*-
"""Stonks_CNN_Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kRfs7kCeEDVcrzmNkI7rCneHWFFDYzld
"""

#!pip install wandb
#import wandb
#wandb.login()
#from wandb.keras import WandbCallback, WandbModelCheckpoint

"""# Importing the necessary"""

import numpy as np
import pandas as pd
import os

import matplotlib.pyplot as plt
import seaborn as sns
import time
import tensorflow as tf
from tensorflow.keras.applications import EfficientNetB7
import tensorflow.keras.layers as tfl
from sklearn.metrics import confusion_matrix
import gdown


#dataframeidx only refers to
def generate_frame(dataframeidx,stonk_names):
  size = len(stonk_names)
  frame = np.zeros([size,size])
  for i in range(size):
    for j in range(i,size):
      frame[i,j] = dataframeidx[stonk_names[i]]*dataframeidx[stonk_names[j]]
      frame[j,i] = frame[i,j]

  ## Below is only to get into RGB format suitable for EfficientNet negative values will be automatically ignored by RELUs so making everything >=0
  frame = frame- np.min(frame)
  frame = frame/np.max(frame)
  return frame


@tf.function
def generate_frame_tf(stonk_tensor):
  frame = tf.tensordot(stonk_tensor,stonk_tensor,axes = 0)
  ## To normalize between 0 and 1 and to regulate extreme accidental correlations. Can consider others
  frame = (1. + tf.math.tanh(frame))*0.5
  return frame


"""### Defining tf functions to generate image of previous 3 min data"""
@tf.function
def generate_image_tf(i,stonk_tensor = df_stonk_tensor):
  image = tf.stack([generate_frame_tf(stonk_tensor[i-1]),generate_frame_tf(stonk_tensor[i-2]),generate_frame_tf(stonk_tensor[i-3])],axis = -1)

  ##Normalizing the image
  image = image - tf.math.reduce_min(image)
  image = (image/tf.math.reduce_max(image))*255
  # 1 refers to AAPL. can chose any other stonk
  target = tf.math.reduce_max([0.,tf.sign(stonk_tensor[i,1])])
  return tf.reshape(image,[size,size,3]), (tf.cast(target, tf.float64), stonk_tensor[i,1])



def G2_classifier(image_shape=IMG_SIZE):
    ''' Define a tf.keras model for binary classification out of the MobileNetV2 model
    Arguments:
        image_shape -- Image width and height
        data_augmentation -- data augmentation function
    Returns:
    Returns:
        tf.keras.model
    '''


    input_shape = image_shape + (3,)

    ### START CODE HERE

    base_model = EfficientNetB7(input_shape=input_shape,
                                                   include_top=False, # <== Important!!!!
                                                   weights='imagenet') # From imageNet

    # Freeze the base model by making it non trainable
    base_model.trainable = False

    # create theinput layer (Same as the imageNetv2 input size)
    inputs = tf.keras.Input(shape=input_shape)


    # data preprocessing using the same weights the model was trained on
    x = preprocess_input(inputs)

    # set training to False to avoid keeping track of statistics in the batch norm layer
    x = base_model(x, training=False)

    # Add the new Binary classification layers
    # use global avg pooling to summarize the info in each channel
    x = tfl.GlobalAveragePooling2D()(x)
    #include dropout with probability of 0.2 to avoid overfitting
    x = tfl.Dropout(0.2)(x)

    # create a prediction layer with one neuron (as a classifier only needs one)
    prediction_layer = tfl.Dense(1,activation = 'sigmoid')
    #prediction_layer = tfl.Dense(1,activation = 'linear') #from logits in fit

    ### END CODE HERE

    pred = prediction_layer(x)
    outputs = [pred, pred]
    model = tf.keras.Model(inputs, outputs)

    return model


def pnl_curve_tensorflow(predictions, price_changes):
    # Ensure inputs are tensors
    predictions = tf.squeeze(tf.convert_to_tensor(predictions, dtype=tf.float32))
    #1 refers to
    price_changes = tf.convert_to_tensor(price_changes, dtype=tf.float32)


    # Calculate daily PnL
    daily_pnl_ob = predictions * (price_changes)
    daily_pnl_bs = ((predictions-0.5)*2) * price_changes
    #print(daily_pnl)

    # Calculate cumulative PnL
    cum_pnl_ob = tf.math.cumprod(daily_pnl_ob+1)
    cum_pnl_bs = tf.math.cumprod(daily_pnl_bs+1)

    return daily_pnl_ob,cum_pnl_ob,daily_pnl_bs,cum_pnl_bs

def train_classifier(config: dict,
          callbacks: list,
          verbose: int=0):
    """
    Utility function to train the model.


    Arguments:
        config (dict): Dictionary of hyperparameters.
        callbacks (list): List of callbacks passed to `model.fit`.
        verbose (int): 0 for silent and 1 for progress bar.
    """


    # Initalize model
    tf.keras.backend.clear_session()
    #model = unet_model_2(input_size=(128,128,1),n_filters=config.nfilters)

    batch_size = config.batch_size
    rtraini = config.itrain
    rtrainf = (config.itrain)+(config.ntrain)
    train = tf.data.Dataset.from_tensor_slices((range(rtraini,rtrainf)))
    val = tf.data.Dataset.from_tensor_slices((range(rtrainf, rtrainf + (config.ntrain)//10)))


    train = train.map(generate_image_tf, num_parallel_calls=1)## Setting this to 1. AUTOTUNE freezing computation
    train = train.batch(batch_size)
    if config.shuffle:
      train = train.shuffle(buffer_size= 100)
    #train_unet = train_unet.prefetch(tf.data.AUTOTUNE)

    val = val.map(generate_image_tf, num_parallel_calls=1)## Setting this to 1. AUTOTUNE freezing computation
    val = val.batch(batch_size)

    #stonk_classifier = tf.keras.models.load_model('/content/drive/MyDrive/Stonks/models/stonk_classifier_base.h5')#G2_classifier(image_shape=(size,size))
    stonk_classifier = G2_classifier(image_shape=(size,size))
    if config.train_all:

      base_model = stonk_classifier.layers[1]
      base_model.trainable = True

      fine_tune_at = 0
      for layer in base_model.layers[:fine_tune_at]:
        layer.trainable = False
      config.init_learning_rate = 0.1*config.init_learning_rate

    stonk_classifier.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=config.init_learning_rate),
              #loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),
              loss=[tf.keras.losses.BinaryCrossentropy(), tf.keras.losses.MeanAbsoluteError()],
              loss_weights = [1, 0],
              metrics=config.metrics)



    # Train the model
    _ = stonk_classifier.fit(train,
                  epochs= config.epochs,
                  validation_data=val,
                  callbacks=callbacks,
                  verbose=verbose)


    return stonk_classifier


def pnl_curve_tensorflow(predictions, price_changes):
    # Ensure inputs are tensors
    predictions = tf.squeeze(tf.convert_to_tensor(predictions, dtype=tf.float32))
    #1 refers to
    price_changes = tf.convert_to_tensor(price_changes, dtype=tf.float32)


    # Calculate daily PnL
    daily_pnl_ob = predictions * (price_changes)
    daily_pnl_bs = ((predictions-0.5)*2) * price_changes
    #print(daily_pnl)

    # Calculate cumulative PnL
    cum_pnl_ob = tf.math.cumprod(daily_pnl_ob+1)
    cum_pnl_bs = tf.math.cumprod(daily_pnl_bs+1)

    return daily_pnl_ob,cum_pnl_ob,daily_pnl_bs,cum_pnl_bs
